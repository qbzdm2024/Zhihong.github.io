
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"I am a fourth-year Ph.D. candidate at the University of Texas at Dallas (UTD). I am fortunate to be advised by Prof.Wei Yang and Prof.Cong Liu. Before joining UTD, I received my master degree from Tongji University in May 2018. My research interest lies in machine learning, computer security, and program analysis.\nI am actively looking for cooperation in the following topics: (1) deploying ML models safely and efficiently on edge/server platforms, (2) developing automatic tools to find the bugs in existing ML infrastructures, and (3) understanding the decision making of ML models and improving them.\nFeel free to drop me an email if we share common research interests.\nDownload my resumé.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a fourth-year Ph.D. candidate at the University of Texas at Dallas (UTD). I am fortunate to be advised by Prof.Wei Yang and Prof.Cong Liu. Before joining UTD, I received my master degree from Tongji University in May 2018.","tags":null,"title":"Simin Chen","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"2a6a4d5bc2855ea896aa69c68fc0f080","permalink":"https://chensimin.site/events/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/events/example/","section":"events","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"events"},{"authors":null,"categories":["Publication"],"content":"","date":1705881600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642809600,"objectID":"9568c46c4860d8c0f60a47074468d197","permalink":"https://chensimin.site/post/getting-started/fse2024_paper/","publishdate":"2024-01-22T00:00:00Z","relpermalink":"/post/getting-started/fse2024_paper/","section":"post","summary":"Our paper, titled \"PPM,\" has been accepted for presentation at ESEC/FSE 2024. PPM introduces a novel approach to benchmarking large language models (LLMs) by advocating for the use of dynamically generated datasets instead of static datasets. Specifically, PPM is designed to benchmark the programming capability of LLMs. PPM propose to merge two existing programming problems to create new one as the benchmark.","tags":["Academic"],"title":"Jan 2024 -- One first authored paper is directly accepted to ESEC/FSE 2024.","type":"post"},{"authors":null,"categories":["Reviewer"],"content":"","date":1705881600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1705881600,"objectID":"36f0020b55e83414a08bfbcbfc33679f","permalink":"https://chensimin.site/post/getting-started/ica3pp_2024_reviewer/","publishdate":"2024-01-22T00:00:00Z","relpermalink":"/post/getting-started/ica3pp_2024_reviewer/","section":"post","summary":"I will serve as a PC for The 24rd International Conference on Algorithms and Architectures for Parallel Processing (ICA3PP 2024).","tags":["Academic"],"title":"Jan 2024 -- Serve as a PC member for the 24rd international conference on algorithms and architectures for parallel processing (ICA3PP 2024)","type":"post"},{"authors":null,"categories":["Publication"],"content":"","date":1705708800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1705708800,"objectID":"1fcb4fe5ff0d4816d82dc5669883c9de","permalink":"https://chensimin.site/post/getting-started/accv2024_reviewer/","publishdate":"2024-01-20T00:00:00Z","relpermalink":"/post/getting-started/accv2024_reviewer/","section":"post","summary":"","tags":["Academic"],"title":"Jan 2024 -- Serve as the reviewer of the 17th Asian Conference on Computer Vision (ACCV 2024)","type":"post"},{"authors":null,"categories":["Publication"],"content":"","date":1705708800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1705708800,"objectID":"b9861e85214c5cbd89a1d3b437adb1f4","permalink":"https://chensimin.site/post/getting-started/eccv2024_reviewer/","publishdate":"2024-01-20T00:00:00Z","relpermalink":"/post/getting-started/eccv2024_reviewer/","section":"post","summary":"","tags":["Academic"],"title":"Jan 2024 -- Serve as the reviewer of the European Conference on Computer Vision 2024 (ECCV 2024)","type":"post"},{"authors":null,"categories":["Reviewer"],"content":"","date":1701388800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669852800,"objectID":"a736137fdd7dc5ab0efa60cd09073869","permalink":"https://chensimin.site/post/getting-started/cvpr_2024_reviewer/","publishdate":"2023-12-01T00:00:00Z","relpermalink":"/post/getting-started/cvpr_2024_reviewer/","section":"post","summary":"I will serve as a Reviewer for the IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR 2024).","tags":["Academic"],"title":"July 2023 -- Serve as a Reviewer for CVPR 2024.","type":"post"},{"authors":null,"categories":["Reviewer"],"content":"","date":1688515200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656979200,"objectID":"3aa1bb4395c957e51766e6127167fde2","permalink":"https://chensimin.site/post/getting-started/aaai_2024_reviewer/","publishdate":"2023-07-05T00:00:00Z","relpermalink":"/post/getting-started/aaai_2024_reviewer/","section":"post","summary":"I will serve as a PC for the Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI 2024).","tags":["Academic"],"title":"July 2023 -- Serve as a PC member for AAAI 2024.","type":"post"},{"authors":null,"categories":["Reviewer"],"content":"","date":1688169600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656633600,"objectID":"9f26bad0bfb6e408260c56ed5621d771","permalink":"https://chensimin.site/post/getting-started/ica3pp_2023_reviewer/","publishdate":"2023-07-01T00:00:00Z","relpermalink":"/post/getting-started/ica3pp_2023_reviewer/","section":"post","summary":"I will serve as a PC for The 23rd International Conference on Algorithms and Architectures for Parallel Processing (ICA3PP 2023).","tags":["Academic"],"title":"June 2023 -- Serve as a PC member for the 23rd international conference on algorithms and architectures for parallel processing (ICA3PP 2023)","type":"post"},{"authors":null,"categories":["Award"],"content":"","date":1685577600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685577600,"objectID":"4a7b560c5597918a6b01c686a3295f85","permalink":"https://chensimin.site/post/getting-started/issta23_travel/","publishdate":"2023-06-01T00:00:00Z","relpermalink":"/post/getting-started/issta23_travel/","section":"post","summary":"I receive the travel grant award from from SIGSOFT for ISSTA 2023.  Thank you, SIGSOFT!","tags":["Academic"],"title":"June 2023 -- Receive the travel grant award from SIGSOFT for ISSTA 2023. Thanks SIGSOFT!","type":"post"},{"authors":["Yiming Chen","Simin Chen","Zexin Li","Wei Yang","Cong Liu","Robby Tan","Haizhou Li"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1683849600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1683849600,"objectID":"63ea41e711e5d2cb66b6f91dd0047838","permalink":"https://chensimin.site/publication/example/2023_acl_same/","publishdate":"2023-05-12T00:00:00Z","relpermalink":"/publication/example/2023_acl_same/","section":"publication","summary":"Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example.","tags":["Adversarial ML","Multimodal Representation"],"title":"Dynamic Transformer Provide a False Sense of Efficiency","type":"publication"},{"authors":null,"categories":["Internship"],"content":"","date":1683849600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589241600,"objectID":"c6ac9ecca97aa79f3e1c758d15127d41","permalink":"https://chensimin.site/post/getting-started/amazon/","publishdate":"2023-05-12T00:00:00Z","relpermalink":"/post/getting-started/amazon/","section":"post","summary":"I will join the [Amazon Web Services](https://aws.amazon.com/cn/) as a applied scientist intern from June 2023 to August 2023, under the supervision of [Michael Hicks](https://mhicks.me/) and [Emina Torlak](https://homes.cs.washington.edu/~emina/) on the project of [Cedar](https://www.cedarpolicy.com/en)","tags":["Academic"],"title":"May 2023 -- I will take my summer internship at Amazon, under the supervision of Michael Hicks and Emina Torlak.","type":"post"},{"authors":null,"categories":["Publication"],"content":"","date":1683849600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1683849600,"objectID":"794844780c22b74eefbdbc5a1bb1f8a6","permalink":"https://chensimin.site/post/getting-started/acl2023_paper/","publishdate":"2023-05-12T00:00:00Z","relpermalink":"/post/getting-started/acl2023_paper/","section":"post","summary":"","tags":["Academic"],"title":"May 2023 -- One paper has been accepted to ACL 2023.","type":"post"},{"authors":null,"categories":["Publication"],"content":"","date":1682985600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682985600,"objectID":"d16063be47253d5392ff5ae51ea23bb8","permalink":"https://chensimin.site/post/getting-started/interspeech-2023_paper/","publishdate":"2023-05-02T00:00:00Z","relpermalink":"/post/getting-started/interspeech-2023_paper/","section":"post","summary":"","tags":["Academic"],"title":"May 2023 -- One paper has been accepted to Interspeech 2023.","type":"post"},{"authors":["Simin Chen","Hanlin Chen","Mirazul Haque","Cong Liu","Wei Yang"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1677456840,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677456840,"objectID":"314639555a4f8856744cc085460ce790","permalink":"https://chensimin.site/publication/example/2023_cvpr_efficfrog/","publishdate":"2023-02-27T00:14:00Z","relpermalink":"/publication/example/2023_cvpr_efficfrog/","section":"publication","summary":"Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example.","tags":["Adversarial ML","Multimodal Representation"],"title":"The Dark Side of Dynamic Routing Neural Networks: Towards Efficiency Backdoor Injection","type":"publication"},{"authors":null,"categories":["Publication"],"content":"","date":1677456000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677456000,"objectID":"09a4f841b9df57642cc7f7ad59a5d724","permalink":"https://chensimin.site/post/getting-started/cvpr2023_paper/","publishdate":"2023-02-27T00:00:00Z","relpermalink":"/post/getting-started/cvpr2023_paper/","section":"post","summary":"We are pleased to announce that our paper on efficiency backdoor attacks and transferability attacks for human face recognition systems has been accepted for presentation at the prestigious Conference on Computer Vision and Pattern Recognition (CVPR) in 2023.","tags":["Academic"],"title":"February 2023 -- Two papers have been accepted to CVPR 2023.","type":"post"},{"authors":["Zexin Li","Bangjie Yin","Taiping Yao","Junfeng Guo","Shouhong Ding","Simin Chen","Cong Liu"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1677456000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677456000,"objectID":"2123a494c7d946c8480634ba7d3b593d","permalink":"https://chensimin.site/publication/example/2023_cvpr_sibling/","publishdate":"2023-02-27T00:00:00Z","relpermalink":"/publication/example/2023_cvpr_sibling/","section":"publication","summary":"Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example.","tags":["Adversarial ML","Multimodal Representation"],"title":"Sibling-Attack: Rethinking Transferable Adversarial Attacks against Face Recognition","type":"publication"},{"authors":null,"categories":["Reviewer"],"content":"","date":1675728000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675728000,"objectID":"2c22e3f84503cfa8fb210e5f6e9ea8c0","permalink":"https://chensimin.site/post/getting-started/iccv2023_reviewer/","publishdate":"2023-02-07T00:00:00Z","relpermalink":"/post/getting-started/iccv2023_reviewer/","section":"post","summary":"I will serve as a reviewer for ICCV 2023.","tags":["Academic"],"title":"February 2023 -- Serve as the reviewer for ICCV 2023.","type":"post"},{"authors":["Simin Chen","Shiyi Wei","Cong Liu","Wei Yang"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1673827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673827200,"objectID":"97b3b5bd4f9cdaf538ec2c8eb545eea9","permalink":"https://chensimin.site/publication/example/2023_issta_-dycl/","publishdate":"2023-01-16T00:00:00Z","relpermalink":"/publication/example/2023_issta_-dycl/","section":"publication","summary":"The deep learning (DL) compiler is a fundamental piece of infrastructure that enables the deployment of deep neural networks on various hardware platforms (e.g., mobile devices and Raspberry Pi). A DL compiler translates DNN programs written with high-level DL frameworks (e.g., PyTorch and TensorFlow) into portable executables; deployed host programs can then flexibly run these executables. Existing DL compilers treat neural network programs as static data flow graphs, which presume a pre-determined DNN model architecture. However, this assumption does not hold in modern dynamic neural networks (DyNNs). As a result, existing DL compilers cannot compile DyNNs into correct executables. To bridge this gap, we propose DyCL, a flexible approach that enables existing DL compilers for compiling DyNNs. DyCL handles the dynamic nature of the DyNNs by introducing a compilation mechanism that redistributes the original programs' control and data flow during compilation. Specifically, DyCL applies program analysis and transformation techniques to transform an dynamic neural network into multiple sub-neural networks. Each sub-neural network does not contain conditional statements and is compiled separately. DyCL then synthesizes a host API to model the control flow of the DyNNs and invocations of the sub-neural networks. Our evaluation demonstrates that DyCL can 100\\% successfully compile all dynamic neural networks and the compiled executables run $1.12\\times$ to $20.21\\times$  faster than the original DyNNs runs on the general-purpose DL frameworks.","tags":["Program Analysis","Software Engineering","AI"],"title":"DyCL: Dynamic Neural Network Compilation Via Program Rewriting  and Graph Optimization","type":"publication"},{"authors":null,"categories":["Publication"],"content":"","date":1673827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673827200,"objectID":"87df6fa3e928149db4b1b17316528046","permalink":"https://chensimin.site/post/getting-started/issta2023_paper/","publishdate":"2023-01-16T00:00:00Z","relpermalink":"/post/getting-started/issta2023_paper/","section":"post","summary":"Our paper, DyCL, is accepted to ISSTA 2023. DyCL is a automatic tool that rewrites the dynamic neural networks for supporting existing DL compilers.","tags":["Academic"],"title":"January 2023 -- One paper is accepted to ISSTA 2023.","type":"post"},{"authors":null,"categories":["Reviewer"],"content":"","date":1671926400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1671926400,"objectID":"54d61d2faeec4a4b60d40fcc31d4a95c","permalink":"https://chensimin.site/post/getting-started/msr_2023_reviewer/","publishdate":"2022-12-25T00:00:00Z","relpermalink":"/post/getting-started/msr_2023_reviewer/","section":"post","summary":"I will serve as a junior PC for MSR 2023.","tags":["Academic"],"title":"December 2022 -- Serve as a Junior PC member for MSR 2023.","type":"post"},{"authors":null,"categories":["Reviewer"],"content":"","date":1668297600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668297600,"objectID":"11d61a1fc5ab0132f3d911bf8ee4e78a","permalink":"https://chensimin.site/post/getting-started/cvpr_2023_reviewer/","publishdate":"2022-11-13T00:00:00Z","relpermalink":"/post/getting-started/cvpr_2023_reviewer/","section":"post","summary":"I will serve as a reviewer member for CVPR 2023.","tags":["Academic"],"title":"November 2022 -- Serve as a reviewer member for CVPR 2023.","type":"post"},{"authors":null,"categories":["Prize"],"content":"","date":1665705600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665705600,"objectID":"4475397754b48ef6c8ebdf714f580924","permalink":"https://chensimin.site/post/getting-started/dao2022/","publishdate":"2022-10-14T00:00:00Z","relpermalink":"/post/getting-started/dao2022/","section":"post","summary":"Our team, SecureDAO, wins the second prize in THUBA DAO Global Summer Hack. Thanks for the contribution of each teammate, It is my first journey in the world of Web 3. Here is the [Twitter News](https://twitter.com/thuba_dao/status/1580880829634383872?s=46\u0026t=j0b1RF5LFRqvT9TEPxBWMg).","tags":["Academic"],"title":"Octorber 2022 -- Our team, SecureDAO, wins the second prize in THUBA DAO Global Hackson. Thanks for the contribution of each teammate.","type":"post"},{"authors":null,"categories":["Publication"],"content":"","date":1661817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661817600,"objectID":"1d5011ada73df8dbe70dea48d2def258","permalink":"https://chensimin.site/post/getting-started/ase2022_paper/","publishdate":"2022-08-30T00:00:00Z","relpermalink":"/post/getting-started/ase2022_paper/","section":"post","summary":"Our paper, DeepPerform, is accepted to ASE 2022. DeepPerform is designed to test the performance robustness of adaptive neural networks.","tags":["Academic"],"title":"April 2022 -- One paper is accepted to ASE 2022.","type":"post"},{"authors":["Simin Chen","Mirazul Haque","Cong Liu","Wei Yang"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1661817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661817600,"objectID":"d3f4ce304141e4797eb3b1965fd87204","permalink":"https://chensimin.site/publication/example/2022_ase_-deepperform/","publishdate":"2022-09-01T00:00:00Z","relpermalink":"/publication/example/2022_ase_-deepperform/","section":"publication","summary":"Today, an increasing number of Adaptive Deep Neural Networks (AdNNs) are being used to make decisions on resource-constrained embedded devices. We observe that, similar to traditional software, redundant computations exist in AdNNs, resulting in considerable performance degradation. The performance degradation in AdNNs is dependent on the input workloads, and is referred to as input-dependent performance bottlenecks (IDPBs). To ensure an AdNN satisfies the performance requirements of real-time applications, it is essential to conduct performance testing to detect IDPBs in the AdNN.  Existing neural network testing methods are primarily concerned with correctness testing, which does not involve performance testing. To fill this gap, we propose \\tool, a scalable approach to generate test samples to detect the IDPB of AdNNs. We first demonstrate how the problem of generating performance test samples detecting IDPBs can be formulated as an optimization problem. Following that, we demonstrate how tool efficiently handles the optimization problem by learning and estimating the distribution of AdNNs' computational consumption. We evaluate \\tool on three widely used datasets against five popular AdNN models. The results show that \\tool generates test samples that cause more severe performance degradation~(FLOPs increase up to 552\\%). Furthermore, \\tool is substantially more efficient than the baseline methods in terms of generating test inputs (runtime overhead only 6–10 milliseconds).","tags":["Program Analysis","Software Engineering","AI"],"title":"DeepPerform: An Efficient Approach for Performance Testing of Resource-Constrained Neural Networks","type":"publication"},{"authors":null,"categories":["Reviewer"],"content":"","date":1659916800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659916800,"objectID":"80b74e91068c3e84eaf653d051d06cce","permalink":"https://chensimin.site/post/getting-started/aaai_2023_reviewer/","publishdate":"2022-08-08T00:00:00Z","relpermalink":"/post/getting-started/aaai_2023_reviewer/","section":"post","summary":"I will serve as a Program Committee (PC) Member for AAAI-2023","tags":["Academic"],"title":"August 2022 -- Serve as a PC member for AAAI 2023.","type":"post"},{"authors":null,"categories":["Reviewer"],"content":"","date":1657152000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657152000,"objectID":"89e18cb1dc5a623570966b7f64da6185","permalink":"https://chensimin.site/post/getting-started/wacv2022/","publishdate":"2022-07-07T00:00:00Z","relpermalink":"/post/getting-started/wacv2022/","section":"post","summary":"I will Serve as an reviewer of WACV 2022.","tags":["Academic"],"title":"July 2022 -- Serve as a reviewer of WACV 2022.","type":"post"},{"authors":null,"categories":["Publication"],"content":"","date":1655164800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1655164800,"objectID":"3e766c8c7f8b58ee2a8b020aa770c407","permalink":"https://chensimin.site/post/getting-started/fse22_nmtsloth/","publishdate":"2022-06-14T00:00:00Z","relpermalink":"/post/getting-started/fse22_nmtsloth/","section":"post","summary":"Our paper, NMTSloth, is accepted to ESEC/FSE 2022. NMTSloth is designed to test the performance degradation bugs in neural machine translation systems. We show NMTSloth can generate generate inputs that increase neural machine translation systems computational consumption upto 3153%.","tags":["Academic"],"title":"June 2022 -- One paper is accepted to ESEC/FSE 2022.","type":"post"},{"authors":["Simin Chen","Cong Liu","Mirazul Haque","Zihe Song","Wei Yang"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1655164800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1655164800,"objectID":"b1e8ca2806f818b4478066734c631560","permalink":"https://chensimin.site/publication/example/2022_fse_-nmtsloth/","publishdate":"2020-06-14T00:00:00Z","relpermalink":"/publication/example/2022_fse_-nmtsloth/","section":"publication","summary":"Neural Machine Translation (NMT) systems have received much recent attention due to their human-level accuracy. While existing works mostly focus on either improving accuracy or testing accuracy robustness, the computation efficiency of NMT systems, which is of paramount importance due to often vast translation demands and real-time requirements, has surprisingly received little attention. In this paper, we make the first attempt in understanding and testing potential computation efficiency robustness in state-of-the-art NMT systems. By analyzing the working mechanism and implementation of 1455 publicly-accessible NMT systems, we observe a fundamental property that could be manipulated in an adversarial manner to significantly reduce computation efficiency. An interesting observation is that the computation efficiency of NMT systems is determined by the output length instead of the input, where the output length depends on two factors i.e., an often sufficiently large yet pessimistic pre-configured threshold controlling the max number of iterations, and a runtime generated end of sentence (EOS) token. Our key motivation is to generate test inputs that could sufficiently delay the generation of EOS such that NMT systems would have to go through enough iterations to satisfy the pre-configured threshold. We present NMTSloth which develops a gradient-guided technique that searches for a minimal and unnoticeable perturbation at character-level, token-level, and structure-level, which sufficiently delay the appearance of EOS and force these inputs to reach the naturally-unreachable threshold. To demonstrate the effectiveness of NMTSloth, we conduct a systematic evaluation on three public-available NMT systems. Experimental results show that NMTSloth can increase NMT systems' response latency and energy consumption by 85% to 3153% and 86% to 3052%, respectively, by perturbing just one to three tokens in any input sentences.","tags":["Program Analysis","Software Engineering","AI"],"title":"NMTSloth: Understanding and Testing Efficiency Degradation of Neural Machine Translation Systems","type":"publication"},{"authors":null,"categories":["Award"],"content":"","date":1651190400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651190400,"objectID":"f6fd718ae7c65f65f47dd4baae20b422","permalink":"https://chensimin.site/post/getting-started/cvpr22_travel/","publishdate":"2022-04-29T00:00:00Z","relpermalink":"/post/getting-started/cvpr22_travel/","section":"post","summary":"I receive the travel grant award from CVPR22. Thank you, CVPR22!","tags":["Academic"],"title":"April 2022 -- Receive the travel grant award from CVPR22","type":"post"},{"authors":null,"categories":["Publication"],"content":"","date":1650585600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650585600,"objectID":"c7b1444d27f0d2448a3acaa736b2504d","permalink":"https://chensimin.site/post/getting-started/ijcai2022/","publishdate":"2022-04-22T00:00:00Z","relpermalink":"/post/getting-started/ijcai2022/","section":"post","summary":"Our paper, NNReverse, is accepted to IJCAI 2022. NNReverse is an automatic approach for reversing DNNs from AI programs.","tags":["Academic"],"title":"April 2022 -- One paper is accepted to IJCAI 2022.","type":"post"},{"authors":["Simin Chen","Hamed Khanpour","Cong Liu","Wei Yang"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1650499200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650499200,"objectID":"388c59cc8aead43e7d383ce5567efc27","permalink":"https://chensimin.site/publication/example/2022_ijcai_nnreverse/","publishdate":"2020-04-21T00:00:00Z","relpermalink":"/publication/example/2022_ijcai_nnreverse/","section":"publication","summary":"With the privatization deployment of DNNs on edge devices, the security of on-device DNNs has raised great concern. To quantify model leakage risk of on-device DNNs automatically, we propose NNReverse, the first learning-based method which can reverse DNNs from AI programs without domain knowledge. NNReverse trains a representation model to represent the semantic of binary codes for DNN layers. By searching the most similar function in our database, NNReverse infers the layer type of a given functions’ binary codes. To represent assembly instructions semantic precisely, NNReverse propose a more fine-grained embedding model to represent the textual and structural semantic of assembly functions.","tags":["Program Analysis","Software Engineering","AI"],"title":"Learning to Reverse DNNs from AI Programs Automatically","type":"publication"},{"authors":null,"categories":["Reviewer"],"content":"","date":1649635200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649635200,"objectID":"4eb4dbd6611c5cc5faebcec50c090d53","permalink":"https://chensimin.site/post/getting-started/eccv2022/","publishdate":"2022-04-11T00:00:00Z","relpermalink":"/post/getting-started/eccv2022/","section":"post","summary":"I will Serve as an reviewer of ECCV 2022.","tags":["Academic"],"title":"April 2022 -- Serve as a reviewer of ECCV 2022.","type":"post"},{"authors":null,"categories":["Publication"],"content":"","date":1649203200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649203200,"objectID":"79a7feb049a1a19794a88c16e5e58757","permalink":"https://chensimin.site/post/getting-started/icse2022_volunteer/","publishdate":"2022-04-06T00:00:00Z","relpermalink":"/post/getting-started/icse2022_volunteer/","section":"post","summary":"","tags":["Academic"],"title":"April 2022 -- Serve as a student volunteer in ICSE 2022","type":"post"},{"authors":null,"categories":["Publication"],"content":"","date":1649203200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658275200,"objectID":"2d921dbb97d85ac91561615cf42b3f50","permalink":"https://chensimin.site/service/getting-started/pc/","publishdate":"2022-04-06T00:00:00Z","relpermalink":"/service/getting-started/pc/","section":"service","summary":"","tags":["Academic"],"title":"Program Committee Member -- CVPR 2024, AAAI 2024, ICA3PP 2023, ICCV 2023, MSR 2023, CVPR 2023, AAAI 2023, WACV 2022, ECCV 2022","type":"service"},{"authors":null,"categories":["Publication"],"content":"","date":1649203200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689811200,"objectID":"0903bbf41aa76c416b0c13aa1cf7651e","permalink":"https://chensimin.site/service/getting-started/sub_reviewer/","publishdate":"2022-04-06T00:00:00Z","relpermalink":"/service/getting-started/sub_reviewer/","section":"service","summary":"","tags":["Academic"],"title":"Sub-Reviewer -- ISSRE 2023, ASE 2023, ICSE 2023, ICST 2023, ASE 2022, ICST 2022, ICSE 2021","type":"service"},{"authors":["Simin Chen","Zihe Song","Mirazul Haque","Cong Liu","Wei Yang"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1646784000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646784000,"objectID":"7c42f111dc7c4665a124b2723ea087e6","permalink":"https://chensimin.site/publication/example/2022_cvpr_nicgslowdown/","publishdate":"2022-03-09T00:00:00Z","relpermalink":"/publication/example/2022_cvpr_nicgslowdown/","section":"publication","summary":"Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example.","tags":["Adversarial ML","Multimodal Representation"],"title":"NICGSlowDown: Evaluating the Efficiency Robustness of Neural Caption Generation Models","type":"publication"},{"authors":null,"categories":["Publication"],"content":"","date":1646265600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646265600,"objectID":"948bc9f04a51248d64afefb5dca352e1","permalink":"https://chensimin.site/post/getting-started/cvpr2022_paper/","publishdate":"2022-03-03T00:00:00Z","relpermalink":"/post/getting-started/cvpr2022_paper/","section":"post","summary":"Our paper, NICGSlowDown, is accepted to CVPR 2022. To the best of our knowledge, NICGSlowDown is the first work to evaluate the efficiency robustness of neural caption generation models.","tags":["Academic"],"title":"March 2022 -- One paper is accepted to CVPR 2022.","type":"post"},{"authors":null,"categories":["Internship"],"content":"","date":1616112000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584576000,"objectID":"4f9c2cf5373d458f386856a5b7e71c3d","permalink":"https://chensimin.site/post/getting-started/microsoft/","publishdate":"2021-03-19T00:00:00Z","relpermalink":"/post/getting-started/microsoft/","section":"post","summary":"I will join Microsoft Research and work on the project of reversing neural networks.","tags":["Academic"],"title":"March 2021 -- Internship in Microsoft Research.","type":"post"},{"authors":null,"categories":["Publication"],"content":"","date":1604966400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604966400,"objectID":"bd7ccaadf24d5cdd4847b7be31664a87","permalink":"https://chensimin.site/post/getting-started/icse2021_reviewer/","publishdate":"2020-11-10T00:00:00Z","relpermalink":"/post/getting-started/icse2021_reviewer/","section":"post","summary":"I will serve as a Committee Member in Additional Reviewers within the Technical Track-track in ICSE 2021","tags":["Academic"],"title":"November 2020 -- Serve as an additional reviewers in ICSE 2021 technical track.","type":"post"},{"authors":["Simin Chen","Soroush Bateni","Sampath Grandhi","Xiaodi Li","Cong Liu","Wei Yang"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1604880000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604880000,"objectID":"2417cbf7ca800b199360653700190689","permalink":"https://chensimin.site/publication/example/2020_fse_denas/","publishdate":"2020-11-09T00:00:00Z","relpermalink":"/publication/example/2020_fse_denas/","section":"publication","summary":"Deep neural networks (DNNs) have been widely applied in the software development process to automatically learn patterns from massive data. However, many applications still make decisions based on rules that are manually crafted and verified by domain experts due to safety or security concerns. In this paper, we aim to close the gap between DNNs and rule-based systems by automating the rule generation process via extracting knowledge from well-trained DNNs. Existing techniques with similar purposes either rely on specific DNNs input instances or use inherently unstable random sampling of the input space. Therefore, these approaches either limit the exploration area to a local decision-space of the DNNs or fail to converge to a consistent set of rules. The resulting rules thus lack representativeness and stability. In this paper, we address the two aforementioned shortcomings by discovering a global property of the DNNs and use it to remodel the DNNs decision-boundary. We name this property as the activation probability, and show that this property is stable. With this insight, we propose an approach named DENAS including a novel rule-generation algorithm. Our proposed algorithm approximates the non-linear decision boundary of DNNs by iteratively superimposing a linearized optimization function. We evaluate the representativeness, stability, and accuracy of DENAS against five state-of-the-art techniques (LEMNA, Gradient, IG, DeepTaylor, and DTExtract) on three software engineering and security applications Binary analysis, PDF malware detection, and Android malware detection. Our results show that DENAS can generate more representative rules consistently in a more stable manner over other approaches. We further offer case studies that demonstrate the applications of DENAS such as debugging faults in the DNNs and generating signatures that can detect zero-day malware.","tags":["Explanable ML","Software Sngineering"],"title":"DENAS: automated rule generation by knowledge extraction from neural networks","type":"publication"},{"authors":null,"categories":["Publication"],"content":"","date":1589068800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589068800,"objectID":"d22bf418270a9e6136632090d1f60d08","permalink":"https://chensimin.site/post/getting-started/denas/","publishdate":"2020-05-10T00:00:00Z","relpermalink":"/post/getting-started/denas/","section":"post","summary":"Our paper, DENAS, is accepted to ESEC/FSE 2020. DENAS is designed to extract human-understandable rules from well-trained DNNs. Furthermore, DENAS can help model developers locate the DNN bugs and fix the DNN bugs through targeted retraining.","tags":["Academic"],"title":"May 2020 -- One paper is accepted to ESEC/FSE 2020.","type":"post"},{"authors":null,"categories":["Internship"],"content":"","date":1578009600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578009600,"objectID":"07c57e7137c7851e64a78a4d6b813dc1","permalink":"https://chensimin.site/post/getting-started/nec/","publishdate":"2020-01-03T00:00:00Z","relpermalink":"/post/getting-started/nec/","section":"post","summary":"I will join the [Data Science \u0026 System Security](https://www.nec-labs.com/research-departments/data-science-system-security/data-science-systems-research-home) lab in NEC America as a research intern from Jan 2020 to May 2020.","tags":["Academic"],"title":"January 2020 -- Internship in NEC America.","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://chensimin.site/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"Deep neural networks (DNNs) have been widely applied in the software development process to automatically learn patterns from massive data. However, many applications still make decisions based on rules that are manually crafted and verified by domain experts due to safety or security concerns. In this paper, we aim to close the gap between DNNs and rule-based systems by automating the rule generation process via extracting knowledge from well-trained DNNs. Existing techniques with similar purposes either rely on specific DNNs input instances or use inherently unstable random sampling of the input space. Therefore, these approaches either limit the exploration area to a local decision-space of the DNNs or fail to converge to a consistent set of rules. The resulting rules thus lack representativeness and stability.\nIn this paper, we address the two aforementioned shortcomings by discovering a global property of the DNNs and use it to remodel the DNNs decision-boundary. We name this property as the activation probability, and show that this property is stable. With this insight, we propose an approach named DENAS including a novel rule-generation algorithm. Our proposed algorithm approximates the non-linear decision boundary of DNNs by iteratively superimposing a linearized optimization function.\nWe evaluate the representativeness, stability, and accuracy of DENAS against five state-of-the-art techniques (LEMNA, Gradient, IG, DeepTaylor, and DTExtract) on three software engineering and security applications: Binary analysis, PDF malware detection, and Android malware detection. Our results show that DENAS can generate more representative rules consistently in a more stable manner over other approaches. We further offer case studies that demonstrate the applications of DENAS such as debugging faults in the DNNs and generating signatures that can detect zero-day malware.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"0f372349b56a09892efb599076fa4e58","permalink":"https://chensimin.site/aaa/denas/2019_1_denas/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/aaa/denas/2019_1_denas/","section":"aaa","summary":"Explaining the decision making of deep neural networks via rule extraction.","tags":["Explainable ML","DNN Analysis/Testing"],"title":"Automated Rule Generation by Knowledge Extraction from Neural Networks","type":"aaa"},{"authors":null,"categories":null,"content":"Deep neural networks (DNNs) have been widely applied in the software development process to automatically learn patterns from massive data. However, many applications still make decisions based on rules that are manually crafted and verified by domain experts due to safety or security concerns. In this paper, we aim to close the gap between DNNs and rule-based systems by automating the rule generation process via extracting knowledge from well-trained DNNs. Existing techniques with similar purposes either rely on specific DNNs input instances or use inherently unstable random sampling of the input space. Therefore, these approaches either limit the exploration area to a local decision-space of the DNNs or fail to converge to a consistent set of rules. The resulting rules thus lack representativeness and stability.\nIn this paper, we address the two aforementioned shortcomings by discovering a global property of the DNNs and use it to remodel the DNNs decision-boundary. We name this property as the activation probability, and show that this property is stable. With this insight, we propose an approach named DENAS including a novel rule-generation algorithm. Our proposed algorithm approximates the non-linear decision boundary of DNNs by iteratively superimposing a linearized optimization function.\nWe evaluate the representativeness, stability, and accuracy of DENAS against five state-of-the-art techniques (LEMNA, Gradient, IG, DeepTaylor, and DTExtract) on three software engineering and security applications: Binary analysis, PDF malware detection, and Android malware detection. Our results show that DENAS can generate more representative rules consistently in a more stable manner over other approaches. We further offer case studies that demonstrate the applications of DENAS such as debugging faults in the DNNs and generating signatures that can detect zero-day malware.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"bb6caa8336bae1468702335b032a5dc8","permalink":"https://chensimin.site/project/denas/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/denas/","section":"project","summary":"Explaining the decision making of deep neural networks via rule extraction.","tags":["Explainable ML"],"title":"Automated Rule Generation by Knowledge Extraction from Neural Networks","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"82211093a9089ebd2c26246a1ba4f2fa","permalink":"https://chensimin.site/project/adnn/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/adnn/","section":"project","summary":"Deploy DNNs on resource constrainted devices for edge intelligence.","tags":["Edge Intelligence"],"title":"Boosting DL compilers for adaptive neural networks","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"19d348a557a6acde72d37c2d2dd86c05","permalink":"https://chensimin.site/aaa/embedding/2019_2_embedding/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/aaa/embedding/2019_2_embedding/","section":"aaa","summary":"Study the reusability of pre-trained code embeddings","tags":["Deep Learning"],"title":"Characterizing the Reusability of Code Embeddings","type":"aaa"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e8f8a33f1068e8bda34468c45bd470e4","permalink":"https://chensimin.site/aaa/adnn/2022_2_adnn/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/aaa/adnn/2022_2_adnn/","section":"aaa","summary":"Deploy DNNs on resource constrainted devices for edge intelligence.","tags":["Deep Learning"],"title":"Edge Intelligence","type":"aaa"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"c1bc5eff43fa21931bdeefb42640334c","permalink":"https://chensimin.site/aaa/nicgslowdown/2021_2_nicgslowdown/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/aaa/nicgslowdown/2021_2_nicgslowdown/","section":"aaa","summary":"Evaluating the efficiency/energy Robustness of Neural Caption Generation Models","tags":["DNN Analysis/Testing"],"title":"Evaluating the Efficiency Robustness of Neural Caption Generation Models","type":"aaa"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"86c7cd0e350d6b6a3fe43f57b60cf580","permalink":"https://chensimin.site/project/nicgslowdown/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/nicgslowdown/","section":"project","summary":"Evaluating the efficiency/energy Robustness of Neural Caption Generation Models","tags":["DNNs Testing"],"title":"Evaluating the Efficiency Robustness of Neural Caption Generation Models","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"4d252454ad5d5857aba044badc1c106a","permalink":"https://chensimin.site/aaa/codeexplain/2022_1_codeexp/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/aaa/codeexplain/2022_1_codeexp/","section":"aaa","summary":"Design a framework to explain the decision making behind of neural code generation applications.","tags":["Deep Learning"],"title":"Explain Deep Learning Based Code Generation Applications","type":"aaa"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"990d8b3cd22166921f2fc5747458410b","permalink":"https://chensimin.site/project/codeexplain/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/codeexplain/","section":"project","summary":"Design a framework to explain the decision making behind of neural code generation applications.","tags":["Explainable ML"],"title":"Explain Deep Learning Based Code Generation Applications","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8db1856790a0b8d5f526964a56fa549c","permalink":"https://chensimin.site/aaa/nmt/2021_1_nmt/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/aaa/nmt/2021_1_nmt/","section":"aaa","summary":"Understanding and Exploiting the Availability Vulnerability in modern neural machine translation systems.","tags":["DNN Analysis/Testing"],"title":"Exploiting the Availability Vulnerability in Neural Machine Translation Systems","type":"aaa"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"6a504221fcb51f539e2f2d10d5dc3f5e","permalink":"https://chensimin.site/project/nmt/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/nmt/","section":"project","summary":"Understanding and Exploiting the Availability Vulnerability in modern neural machine translation systems.","tags":["DNNs Testing"],"title":"Exploiting the Availability Vulnerability in Neural Machine Translation Systems","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"eedecb471ad5d6b14135ee708545fa7f","permalink":"https://chensimin.site/aaa/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/aaa/external-project/","section":"aaa","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"aaa"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"6b7387f565616d81cea1c93d6b69332a","permalink":"https://chensimin.site/aaa/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/aaa/internal-project/","section":"aaa","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"aaa"}]